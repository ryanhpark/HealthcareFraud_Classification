{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "beneficiary = pd.read_csv(\n",
    "    '../data/Train_Beneficiarydata-1542865627584.csv')\n",
    "inpatient =  pd.read_csv(\n",
    "    '../data/Train_Inpatientdata-1542865627584.csv')\n",
    "outpatient =  pd.read_csv(\n",
    "    '../data/Train_Outpatientdata-1542865627584.csv')\n",
    "target = pd.read_csv('../data/Train-1542865627584.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explore_df(df):\n",
    "    print('Shape:', df.shape, '\\n')\n",
    "    print('Columns and dtypes:\\n', df.dtypes, '\\n')\n",
    "\n",
    "    percent_missing = df.isna().mean().round(4) * 100\n",
    "    print('Columns with Missingness:\\n',\n",
    "          percent_missing[percent_missing > 0.00\n",
    "                         ].sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_parser(df, cols):\n",
    "    for col in cols:\n",
    "        df[col] = pd.to_datetime(df[col])\n",
    "\n",
    "date_parser(beneficiary, ['DOB', 'DOD'])\n",
    "date_parser(inpatient, ['ClaimStartDt', 'ClaimEndDt', 'AdmissionDt', 'DischargeDt'])\n",
    "date_parser(outpatient, ['ClaimStartDt', 'ClaimEndDt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_obj_dtypes(*dfs):\n",
    "    for df in dfs:\n",
    "        object_cols = df.select_dtypes('object').columns.tolist()\n",
    "\n",
    "        for col in object_cols:\n",
    "            val_counts = df[col].apply(type).value_counts()\n",
    "            if len(val_counts) > 1:\n",
    "                print(f'{\"-\" * 40}\\n', val_counts, f'\\n{\"-\" * 40}\\n')\n",
    "            else:\n",
    "                print(val_counts, '\\n')\n",
    "\n",
    "# Highlighted columns all contain two dtypes because they have NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     ONLY DUMMIFY AND CONSOLIDATE IF THERE IS NO RELATIONSHIP BETWEEN THE SINGLE COLS\n",
    "#     AND THE TARGET VARIABLE\n",
    "\n",
    "def dummify(*dfs):\n",
    "    for df in dfs:\n",
    "        procedure_cols = df.columns[df.columns.str.contains('Procedure')].to_list()\n",
    "        diagnosis_cols = df.columns[df.columns.str.contains('ClmDiagnosis')].to_list()\n",
    "\n",
    "        df[procedure_cols] = df[procedure_cols].fillna(0).astype(int)\n",
    "        for col in procedure_cols:\n",
    "            df.loc[df[col] > 0, [col]] = 1\n",
    "        \n",
    "        df[diagnosis_cols] = df[diagnosis_cols].fillna(0)\n",
    "        for col in diagnosis_cols:\n",
    "            df.loc[df[col] != 0, [col]] = 1\n",
    "\n",
    "# dummify(inpatient, outpatient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     ONLY DUMMIFY AND CONSOLIDATE IF THERE IS NO RELATIONSHIP BETWEEN THE SINGLE COLS\n",
    "#     AND THE TARGET VARIABLE\n",
    "\n",
    "def consolidate(*dfs):\n",
    "    for df in dfs:\n",
    "        procedure_cols = df.columns[df.columns.str.contains('Procedure')].to_list()\n",
    "        diagnosis_cols = df.columns[df.columns.str.contains('ClmDiagnosis')].to_list()\n",
    "        physician_cols = df.columns[df.columns.str.contains('OperatingPhysician')\n",
    "                                   | df.columns.str.contains('OtherPhysician')].to_list()\n",
    "        \n",
    "        df['NumProcedureCodes'] = df[procedure_cols].sum(axis=1)\n",
    "        df['NumDiagnosisCodes'] = df[diagnosis_cols].sum(axis=1)\n",
    "        df['NumDoctors']        = df[physician_cols].sum(axis=1) + 1 # +1 includes Attending\n",
    "\n",
    "        df.drop(procedure_cols, axis=1, inplace=True)\n",
    "        df.drop(diagnosis_cols, axis=1, inplace=True)\n",
    "        df.drop(physician_cols, axis=1, inplace=True)\n",
    "        \n",
    "# consolidate(inpatient, outpatient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "beneficiary.loc[beneficiary.RenalDiseaseIndicator == '0', 'RenalDiseaseIndicator'] = 0\n",
    "beneficiary.loc[beneficiary.RenalDiseaseIndicator == 'Y', 'RenalDiseaseIndicator'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = beneficiary.columns[beneficiary.columns.str.contains('Gender')\n",
    "            | beneficiary.columns.str.contains('Race')\n",
    "            | beneficiary.columns.str.contains('RenalDiseaseIndicator')\n",
    "            | beneficiary.columns.str.contains('State')\n",
    "            | beneficiary.columns.str.contains('County')\n",
    "            | beneficiary.columns.str.contains('Chronic')].to_list()\n",
    "\n",
    "beneficiary[cols] = \\\n",
    "    beneficiary[cols].apply(lambda x: x.astype('category'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cols_by_dtype(df):\n",
    "    numeric_cols = df.select_dtypes(np.number)\n",
    "    categorical_cols = df.select_dtypes(['object', 'category'])\n",
    "    numeric_cols = numeric_cols.columns.to_list()\n",
    "    categorical_cols = categorical_cols.columns.to_list()\n",
    "    return numeric_cols, categorical_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "inpatient['IsOutpatient'] = '0'\n",
    "outpatient['IsOutpatient'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "claims = pd.concat([inpatient, outpatient])\n",
    "claims = pd.merge(claims, beneficiary, on='BeneID')\n",
    "claims = pd.merge(claims, target, on='Provider')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols, categorical_cols = cols_by_dtype(claims)[0], cols_by_dtype(claims)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pickling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['claims.pkl']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(claims, 'claims.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
